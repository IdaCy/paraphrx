2025-06-23 18:57:49,748  INFO  ==== run started ====
2025-06-23 18:57:49,748  INFO  input=a_data/alpaca/slice_500/extra_a.json  output=c_assess_inf/output/alpaca_prxed/gemma-2-9b-it/extra_a.json  model=google/gemma-2-9b-it  batch=256  max_tokens=128  temp=0.0  quant=4bit
2025-06-23 18:57:49,856  WARNING  Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-06-23 18:57:51,265  INFO  Flash-Attention 2 not found â†’ using standard attention
2025-06-23 18:57:52,392  INFO  We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-23 19:41:12,600  INFO  Processed 6400 / 14970 prompts
2025-06-23 20:27:37,626  INFO  Processed 12800 / 14970 prompts

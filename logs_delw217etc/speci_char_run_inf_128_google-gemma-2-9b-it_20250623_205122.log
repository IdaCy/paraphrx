2025-06-23 20:51:22,144  INFO  ==== run started ====
2025-06-23 20:51:22,144  INFO  input=a_data/alpaca/slice_500/speci_char.json  output=c_assess_inf/output/alpaca_prxed/gemma-2-9b-it/speci_char.json  model=google/gemma-2-9b-it  batch=128  max_tokens=128  temp=0.0  quant=4bit
2025-06-23 20:51:22,235  WARNING  Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-06-23 20:51:23,629  INFO  Flash-Attention 2 not found â†’ using standard attention
2025-06-23 20:51:24,720  INFO  We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-23 21:00:57,607  INFO  Processed 3200 / 16467 prompts
2025-06-23 21:10:20,494  INFO  Processed 6400 / 16467 prompts
2025-06-23 21:19:49,826  INFO  Processed 9600 / 16467 prompts
2025-06-23 21:29:28,558  INFO  Processed 12800 / 16467 prompts
2025-06-23 21:39:33,740  INFO  Processed 16000 / 16467 prompts

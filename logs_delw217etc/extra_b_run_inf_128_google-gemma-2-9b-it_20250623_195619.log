2025-06-23 19:56:19,476  INFO  ==== run started ====
2025-06-23 19:56:19,476  INFO  input=a_data/alpaca/slice_500/extra_b.json  output=c_assess_inf/output/alpaca_prxed/gemma-2-9b-it/extra_b.json  model=google/gemma-2-9b-it  batch=128  max_tokens=128  temp=0.0  quant=4bit
2025-06-23 19:56:19,567  WARNING  Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-06-23 19:56:20,986  INFO  Flash-Attention 2 not found → using standard attention
2025-06-23 19:56:22,033  INFO  We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-23 20:06:18,430  INFO  Processed 3200 / 15469 prompts
2025-06-23 20:16:12,459  INFO  Processed 6400 / 15469 prompts
2025-06-23 20:26:20,187  INFO  Processed 9600 / 15469 prompts
2025-06-23 20:36:48,159  INFO  Processed 12800 / 15469 prompts
2025-06-23 20:46:43,481  INFO  Finished OK – wrote 499 items to c_assess_inf/output/alpaca_prxed/gemma-2-9b-it/extra_b.json
